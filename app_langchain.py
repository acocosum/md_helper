import streamlit as st
import os
from modules.langchain_helper import (
    load_markdown_with_langchain, 
    split_documents, 
    get_openai_embeddings, 
    create_faiss_index,
    get_chat_model,
    create_qa_chain,
    query_knowledge_base
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ (LangChain + FAISS)",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None
if 'file_processed' not in st.session_state:
    st.session_state.file_processed = False
if 'openai_key' not in st.session_state:
    st.session_state.openai_key = ""
if 'api_base' not in st.session_state:
    st.session_state.api_base = ""
if 'qa_chain' not in st.session_state:
    st.session_state.qa_chain = None

# æ ‡é¢˜
st.title("ğŸ“š ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ (LangChain + FAISS)")
st.markdown("ä¸Šä¼ Markdownæ–‡ä»¶ï¼Œé€šè¿‡AIå¿«é€Ÿè·å–çŸ¥è¯†åº“å†…å®¹çš„ç­”æ¡ˆ")

# ä¾§è¾¹æ  - OpenAI APIè®¾ç½®
with st.sidebar:
    st.header("é…ç½®")
    # è·å–API keyå’Œè‡ªå®šä¹‰APIåœ°å€
    api_key = st.text_input("è¾“å…¥OpenAI API Key", type="password", value=st.session_state.openai_key)
    custom_api_base = st.text_input("è‡ªå®šä¹‰APIåœ°å€(å¯é€‰)", value=st.session_state.api_base or "https://40.chatgptsb.net/v1")

    # å¦‚æœç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰APIåœ°å€ï¼Œç¡®ä¿å®ƒåªåŒ…å«åŸºç¡€URLéƒ¨åˆ†
    if custom_api_base and "/chat/completions" in custom_api_base:
        custom_api_base = custom_api_base.replace("/chat/completions", "")
    if custom_api_base and "/embeddings" in custom_api_base:
        custom_api_base = custom_api_base.replace("/embeddings", "")

    if api_key:
        st.session_state.openai_key = api_key
        st.session_state.api_base = custom_api_base
        if custom_api_base:
            st.success(f"APIå·²é…ç½®ï¼šä½¿ç”¨è‡ªå®šä¹‰APIåœ°å€ {custom_api_base}")
        else:
            st.success("APIå·²é…ç½®ï¼šä½¿ç”¨OpenAIå®˜æ–¹API")
    
    st.markdown("---")
    st.markdown("### å‚æ•°è®¾ç½®")
    chunk_size = st.slider("æ–‡æœ¬å—å¤§å°", min_value=100, max_value=1000, value=500, step=100,
                         help="æ¯ä¸ªæ–‡æœ¬å—çš„å­—ç¬¦æ•°é‡")
    chunk_overlap = st.slider("æ–‡æœ¬å—é‡å ", min_value=0, max_value=200, value=50, step=10,
                            help="ç›¸é‚»æ–‡æœ¬å—çš„é‡å å­—ç¬¦æ•°")
    top_k = st.slider("æ£€ç´¢æ•°é‡", min_value=1, max_value=10, value=3, step=1,
                    help="æ¯æ¬¡é—®ç­”æ£€ç´¢çš„ç›¸å…³æ–‡æœ¬å—æ•°é‡")
    
    st.markdown("---")
    st.markdown("### å…³äº")
    st.info("è¿™æ˜¯ä¸€ä¸ªåŸºäºLangChainæ¡†æ¶å’ŒFAISSå‘é‡æ•°æ®åº“çš„ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ï¼Œå°†æ‚¨çš„Markdownç¬”è®°è½¬åŒ–ä¸ºå¯æŸ¥è¯¢çš„çŸ¥è¯†åº“ã€‚")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader("ä¸Šä¼ Markdownæ–‡ä»¶", type=["md"], 
                              help="é€‰æ‹©ä¸€ä¸ªMarkdownæ ¼å¼çš„æ–‡ä»¶")

# å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
if uploaded_file and not st.session_state.file_processed:
    if st.session_state.openai_key:
        with st.spinner("å¤„ç†æ–‡ä»¶ä¸­..."):
            try:
                # ä½¿ç”¨LangChainåŠ è½½å’Œå¤„ç†Markdownæ–‡ä»¶
                with st.status("åŠ è½½Markdownæ–‡ä»¶..."):
                    documents = load_markdown_with_langchain(uploaded_file)
                
                # æ–‡æœ¬åˆ‡åˆ†
                with st.status("åˆ‡åˆ†æ–‡æ¡£..."):
                    chunks = split_documents(documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)
                    st.session_state.doc_chunks = chunks
                
                # åˆ›å»ºåµŒå…¥æ¨¡å‹
                with st.status("åˆå§‹åŒ–åµŒå…¥æ¨¡å‹..."):
                    embeddings = get_openai_embeddings(
                        api_key=st.session_state.openai_key, 
                        api_base=st.session_state.api_base
                    )
                
                # åˆ›å»ºFAISSç´¢å¼•
                with st.status("åˆ›å»ºå‘é‡ç´¢å¼• (FAISS)..."):
                    vectorstore = create_faiss_index(chunks, embeddings)
                    st.session_state.vectorstore = vectorstore
                
                # åˆ›å»ºè¯­è¨€æ¨¡å‹
                with st.status("åˆå§‹åŒ–è¯­è¨€æ¨¡å‹..."):
                    llm = get_chat_model(
                        api_key=st.session_state.openai_key, 
                        api_base=st.session_state.api_base
                    )
                
                # åˆ›å»ºé—®ç­”é“¾
                with st.status("æ„å»ºé—®ç­”é“¾..."):
                    qa_chain = create_qa_chain(llm, vectorstore)
                    st.session_state.qa_chain = qa_chain
                
                # æ›´æ–°çŠ¶æ€
                st.session_state.file_processed = True
                st.success(f"æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…±åˆ‡åˆ†ä¸º{len(chunks)}ä¸ªæ–‡æœ¬å—")
                
            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    else:
        st.warning("è¯·å…ˆè®¾ç½®OpenAI API Key")

# å¦‚æœæ–‡ä»¶å·²å¤„ç†ï¼Œæ˜¾ç¤ºé—®ç­”ç•Œé¢
if st.session_state.file_processed and st.session_state.qa_chain:
    st.markdown("---")
    st.subheader("ğŸ’¬ å‘æ‚¨çš„çŸ¥è¯†åº“æé—®")
    
    # é—®é¢˜è¾“å…¥åŒºåŸŸ
    question = st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šè¿™ä¸ªé¡¹ç›®çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ")
    
    if question:
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                # æŸ¥è¯¢çŸ¥è¯†åº“
                result = query_knowledge_base(question, st.session_state.qa_chain)
                
                # è·å–ç­”æ¡ˆå’Œæ¥æºæ–‡æ¡£
                answer = result["answer"]
                source_docs = result["source_documents"]
                
                # æ˜¾ç¤ºç­”æ¡ˆ
                st.markdown("### å›ç­”")
                st.markdown(answer)
                
                # æ˜¾ç¤ºç›¸å…³å†…å®¹ï¼ˆå¯æŠ˜å ï¼‰
                with st.expander("æŸ¥çœ‹ç›¸å…³æ–‡æœ¬å—"):
                    for i, doc in enumerate(source_docs):
                        st.markdown(f"**æ–‡æœ¬å— {i+1}**")
                        st.info(doc.page_content)
                        st.caption(f"ç›¸å…³åº¦ï¼š{i+1}/{len(source_docs)}")
                        
            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")
